{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6308266,"sourceType":"datasetVersion","datasetId":3629391}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"###!pip uninstall -y numpy\n###!pip install --quiet numpy==1.26.4\n\n###!pip uninstall -y opencv-python opencv-python-headless\n#!pip install --quiet opencv-python-headless==4.8.1.78\n\n#!pip uninstall -y albumentations qudida scikit-image scipy scikit-learn imgaug\n#!pip install --quiet albumentations==1.3.1\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T06:55:01.314118Z","iopub.execute_input":"2025-11-25T06:55:01.314434Z","iopub.status.idle":"2025-11-25T06:55:01.319138Z","shell.execute_reply.started":"2025-11-25T06:55:01.314410Z","shell.execute_reply":"2025-11-25T06:55:01.318294Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"#import os; os._exit(0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T06:55:01.320442Z","iopub.execute_input":"2025-11-25T06:55:01.321244Z","iopub.status.idle":"2025-11-25T06:55:01.332468Z","shell.execute_reply.started":"2025-11-25T06:55:01.321222Z","shell.execute_reply":"2025-11-25T06:55:01.331481Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torchvision\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nimport numpy as np\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom tqdm import tqdm\nimport cv2\nfrom torch.optim.lr_scheduler import CosineAnnealingLR","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T06:55:01.334648Z","iopub.execute_input":"2025-11-25T06:55:01.334887Z","iopub.status.idle":"2025-11-25T06:55:05.210916Z","shell.execute_reply.started":"2025-11-25T06:55:01.334868Z","shell.execute_reply":"2025-11-25T06:55:05.210084Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"torch.backends.cudnn.benchmark = True\n!nvidia-smi","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T06:55:05.211862Z","iopub.execute_input":"2025-11-25T06:55:05.212422Z","iopub.status.idle":"2025-11-25T06:55:05.453556Z","shell.execute_reply.started":"2025-11-25T06:55:05.212390Z","shell.execute_reply":"2025-11-25T06:55:05.452715Z"}},"outputs":[{"name":"stdout","text":"Tue Nov 25 06:55:05 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 570.172.08             Driver Version: 570.172.08     CUDA Version: 12.8     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n| N/A   52C    P8             14W /   70W |       0MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n| N/A   38C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"device = ('cuda' if torch.cuda.is_available else 'cpu')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T06:55:05.456082Z","iopub.execute_input":"2025-11-25T06:55:05.456865Z","iopub.status.idle":"2025-11-25T06:55:05.461624Z","shell.execute_reply.started":"2025-11-25T06:55:05.456837Z","shell.execute_reply":"2025-11-25T06:55:05.460872Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"mask_dir = r\"/kaggle/input/fs2020-runway-dataset/labels/labels/areas/train_labels_1920x1080\"\ntest_mask_dir = r\"/kaggle/input/fs2020-runway-dataset/labels/labels/areas/test_labels_1920x1080\"\nbinary_mask_dir = r\"/kaggle/working/binary_mask\"\nbinary_test_mask_dir = r\"/kaggle/working/binary_test_mask\"\n\ndef convert2Binary(mask_dir, binary_mask_dir):\n    os.makedirs(binary_mask_dir, exist_ok = True)\n    for filename in os.listdir(mask_dir):\n        if not filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n            continue\n        img_path = os.path.join(mask_dir, filename)\n        img = cv2.imread(img_path)\n    \n        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    \n        binary = np.where(gray > 0, 255, 0).astype(np.uint8)\n    \n        cv2.imwrite(os.path.join(binary_mask_dir, filename), binary)\n\n#convert2Binary(test_mask_dir, binary_test_mask_dir)\n#convert2Binary(mask_dir, binary_mask_dir)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T06:55:05.462581Z","iopub.execute_input":"2025-11-25T06:55:05.462858Z","iopub.status.idle":"2025-11-25T06:55:05.473034Z","shell.execute_reply.started":"2025-11-25T06:55:05.462832Z","shell.execute_reply":"2025-11-25T06:55:05.472430Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"\nclass RunwayDataset(Dataset):\n    def __init__(self, img_dir, mask_dir, transform=None):\n        self.img_dir = img_dir\n        self.mask_dir = mask_dir\n        self.transform = transform\n        self.images = os.listdir(img_dir)\n\n    def __len__(self):\n        return len(self.images)\n    \n    def __getitem__(self, index):\n        img_path = os.path.join(self.img_dir, self.images[index])\n        mask_path = os.path.join(self.mask_dir, self.images[index])\n        image = np.array(Image.open(img_path).convert(\"RGB\"))\n        mask = np.array(Image.open(mask_path).convert(\"L\"), dtype=np.float32) / 255.0\n\n        if self.transform is not None:\n            aug = self.transform(image=image, mask=mask)\n            image = aug[\"image\"]\n            mask = aug[\"mask\"]\n            \n        return image, mask\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T06:55:05.473768Z","iopub.execute_input":"2025-11-25T06:55:05.473988Z","iopub.status.idle":"2025-11-25T06:55:05.484208Z","shell.execute_reply.started":"2025-11-25T06:55:05.473968Z","shell.execute_reply":"2025-11-25T06:55:05.483554Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"import torchvision.transforms.functional as TF\n\nclass DoubleConv(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, 3, padding=1, bias=False),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(out_channels, out_channels, 3, padding=1, bias=False),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True),\n        )\n\n    def forward(self, x):\n        return self.conv(x)\n\nclass UNET(nn.Module):\n    def __init__(self, in_channels=3, out_channels=1, features=[64,128,256,512]):\n        super().__init__()\n        self.downs = nn.ModuleList()\n        self.ups = nn.ModuleList()\n        self.pool = nn.MaxPool2d(2)\n\n        for f in features:\n            self.downs.append(DoubleConv(in_channels, f))\n            in_channels = f\n\n        for f in reversed(features):\n            self.ups.append(nn.ConvTranspose2d(f*2, f, kernel_size=2, stride=2))\n            self.ups.append(DoubleConv(f*2, f))\n\n        self.bottleneck = DoubleConv(features[-1], features[-1]*2)\n        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n\n    def forward(self, x):\n        skips = []\n        for down in self.downs:\n            x = down(x)\n            skips.append(x)\n            x = self.pool(x)\n\n        x = self.bottleneck(x)\n        skips = skips[::-1]\n\n        for idx in range(0, len(self.ups), 2):\n            x = self.ups[idx](x)\n            skip = skips[idx//2]\n            if x.shape != skip.shape:\n                x = TF.resize(x, skip.shape[2:])\n            x = torch.cat((skip, x), dim=1)\n            x = self.ups[idx+1](x)\n\n        return self.final_conv(x)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T06:55:05.485088Z","iopub.execute_input":"2025-11-25T06:55:05.485546Z","iopub.status.idle":"2025-11-25T06:55:05.498661Z","shell.execute_reply.started":"2025-11-25T06:55:05.485525Z","shell.execute_reply":"2025-11-25T06:55:05.498113Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"class DiceLoss(nn.Module):\n    def __init__(self, smooth=1e-8):\n        super().__init__()\n        self.smooth = smooth\n\n    def forward(self, preds, targets):\n        preds = torch.sigmoid(preds)\n        intersection = (preds * targets).sum()\n        dice = 1 - (2 * intersection + self.smooth) / (preds.sum() + targets.sum() + self.smooth)\n        return dice.mean()\n\n\nclass TrevskyLoss(nn.Module):\n    def __init__(self, alpha = 0.5, beta = 0.5, smooth = 1e-6):\n        super(TrevskyLoss, self).__init__()\n        self.alpha = alpha\n        self.beta = beta\n        self.smooth = smooth\n\n    def forward(self, inputs, targets):\n        probs = torch.sigmoid(inputs)\n        targets = targets.float()\n\n        tp = (probs*targets).sum(dim = (1,2,3))\n        fp = ((1 - targets)*probs).sum(dim = (1,2,3))\n        fn = ((1-probs)*targets).sum(dim = (1,2,3))\n\n        ti = (self.smooth + tp)/(tp+ self.alpha*fp + self.beta*fn)\n        loss = 1 - ti\n        return loss.mean()\n\n\nclass FocalTrevsky(nn.Module):\n    def __init__(self, alpha = 0.5, beta = 0.5, gamma = 1.33, smooth = 1e-6):\n        super(FocalTrevsky, self).__init__()\n        self.alpha = alpha\n        self.beta = beta\n        self.smooth = smooth\n        self.gamma = gamma\n\n    def forward(self, inputs, targets):\n        probs = torch.sigmoid(inputs)\n        targets = targets.float()\n\n        tp = (probs*targets).sum(dim = (1,2,3))\n        fp = ((1 - targets)*probs).sum(dim = (1,2,3))\n        fn = ((1-probs)*targets).sum(dim = (1,2,3))\n\n        ti = (self.smooth + tp)/(tp+ self.alpha*fp + self.beta*fn)\n        loss = (1 - ti)**self.gamma\n        focalloss = loss.mean()\n        return focalloss\n\n\n\ndef find_best_threshold(model, loader, device=\"cuda\"):\n    model.eval()\n    thresholds = torch.linspace(0.3, 0.8, steps=11)  # 0.30 â†’ 0.80\n    best_th, best_dice = 0.5, -1\n\n    with torch.no_grad():\n        for th in thresholds:\n            dice_score_accum = 0.0\n            batches = 0\n            for x, y in loader:\n                x = x.to(device)\n                y = y.to(device).unsqueeze(1)\n\n                preds = (torch.sigmoid(model(x)) > th).float()\n\n                intersection = (preds * y).sum()\n                dice = (2 * intersection + 1e-8) / ((preds.sum() + y.sum()) + 1e-8)\n\n                dice_score_accum += dice\n                batches += 1\n\n            avg_dice = (dice_score_accum / batches).item()\n            print(f\"Threshold {th:.2f} â†’ Dice: {avg_dice:.4f}\")\n\n            if avg_dice > best_dice:\n                best_dice = avg_dice\n                best_th = float(th)\n\n    print(f\"\\nðŸ”¥ Best Threshold = {best_th:.2f} (Dice={best_dice:.4f})\\n\")\n    model.train()\n    return best_th\n\n\n\ndef check_accuracy(loader, model, device=\"cuda\"):\n    dice = 0\n    with torch.no_grad():\n        for x, y in loader:\n            x = x.to(device)\n            y = y.to(device).unsqueeze(1)\n            preds = torch.sigmoid(model(x))\n            preds = (preds > 0.5).float()\n            intersection = (preds * y).sum()\n            dice += (2*intersection + 1e-8) / (preds.sum() + y.sum() + 1e-8)\n    print(\"DICE SCORE:\", dice/len(loader))\n    model.train()\n\ndef save_sample_predictions(loader, model, folder=\"saved_images/\", device=\"cuda\", num_images_to_save=10, threshold=0.5):\n    os.makedirs(folder, exist_ok=True)\n    model.eval()\n\n    x, y = next(iter(loader))\n    x = x.to(device)\n    y = y.to(device)\n\n    with torch.no_grad():\n        preds = (torch.sigmoid(model(x)) > threshold).float()\n    \n    num_to_save = min(num_images_to_save, x.shape[0])\n    print(f\"Saving {num_to_save} prediction comparisons using threshold={threshold:.2f}\")\n    \n    mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1).to(device)\n    std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1).to(device)\n\n    for i in range(num_to_save):\n        img_tensor = x[i]\n        img_vis = img_tensor * std + mean\n\n        mask_tensor = y[i].unsqueeze(0)\n        pred_tensor = preds[i]\n\n        mask_rgb = mask_tensor.repeat(3, 1, 1)\n        pred_rgb = pred_tensor.repeat(3, 1, 1)\n\n        comparison = torch.cat([img_vis, mask_rgb, pred_rgb], dim=2)\n        torchvision.utils.save_image(comparison, f\"{folder}/comparison_{i}.png\")\n\n    model.train()\n\n\ndef auto_find_max_batch(model, dataset, start=4, max_try=64, device=\"cuda\"):\n    \"\"\"\n    Tries batch sizes: start, start+2, start+4, ... until OOM.\n    Returns the largest stable batch size.\n    \"\"\"\n    batch = start\n    last_good = start\n\n    while batch <= max_try:\n        try:\n            loader = DataLoader(dataset, batch_size=batch, shuffle=True)\n            x, y = next(iter(loader))\n            x = x.to(device)\n            y = y.float().unsqueeze(1).to(device)\n\n            # Run a small forward & backward to test capacity\n            with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n                out = model(x)\n                loss = (out.mean() - y.mean()).abs()\n\n            loss.backward()\n            torch.cuda.empty_cache()\n\n            print(f\"âœ… Batch {batch} worked\")\n            last_good = batch\n            batch += 2  # Increase step size\n\n        except RuntimeError as e:\n            if \"out of memory\" in str(e).lower():\n                print(f\"âŒ OOM at batch {batch}\")\n                torch.cuda.empty_cache()\n                break\n            else:\n                raise e\n\n    return last_good\n\ndef save_predictions_as_imgs(loader, model, folder=\"saved_images/\", device=\"cuda\"):\n    os.makedirs(folder, exist_ok=True)\n    model.eval()\n    for idx, (x, y) in enumerate(loader):\n        x = x.to(device)\n        with torch.no_grad():\n            preds = (torch.sigmoid(model(x)) > 0.5).float()\n        torchvision.utils.save_image(preds, f\"{folder}/pred_{idx}.png\")\n        torchvision.utils.save_image(y.unsqueeze(1), f\"{folder}/mask_{idx}.png\")\n    model.train()\n\npos_weight = torch.tensor([1.0]).to(device)\nbce_loss = nn.BCEWithLogitsLoss(pos_weight = pos_weight)\ndice_loss = DiceLoss()\nfocalTrevsky = FocalTrevsky(alpha = 0.85, beta = 0.15)\nTrevsky = TrevskyLoss(alpha = 0.7, beta = 0.35)\n\ndef loss_fn(preds, targets):\n    bce = bce_loss(preds, targets)\n    dice = dice_loss(preds, targets)\n    focal_trevsky = focalTrevsky(preds, targets)\n    trevsky = Trevsky(preds, targets)\n    return 0.8*bce + 0.2*trevsky\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T06:55:05.499416Z","iopub.execute_input":"2025-11-25T06:55:05.499620Z","iopub.status.idle":"2025-11-25T06:55:05.730974Z","shell.execute_reply.started":"2025-11-25T06:55:05.499605Z","shell.execute_reply":"2025-11-25T06:55:05.730089Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Paths must be changed to match your Kaggle dataset paths:\nTRAIN_IMG_DIR = \"/kaggle/input/fs2020-runway-dataset/1920x1080/1920x1080/train\"\nTRAIN_MASK_DIR = r\"/kaggle/working/binary_mask\"\nTEST_IMG_DIR = \"/kaggle/input/fs2020-runway-dataset/1920x1080/1920x1080/test\"\nTEST_MASK_DIR = \"/kaggle/working/binary_test_mask\"\n\nBATCH_SIZE = 24\nLR = 2e-4\nEPOCHS = 25\nIMG_H, IMG_W = 288, 512\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\ntrain_tf = A.Compose([\n    A.Resize(IMG_H, IMG_W),\n    A.HorizontalFlip(p=0.5),\n    A.RandomBrightnessContrast(p=0.4),\n    A.HueSaturationValue(p=0.3),\n    A.Rotate(limit=8, p=0.4),\n    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0),\n    ToTensorV2(),\n])\n\ntest_tf = A.Compose([\n    A.Resize(IMG_H, IMG_W),\n    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0),\n    ToTensorV2(),\n])\n\ntrain_ds = RunwayDataset(TRAIN_IMG_DIR, TRAIN_MASK_DIR, train_tf)\ntest_ds = RunwayDataset(TEST_IMG_DIR, TEST_MASK_DIR, test_tf)\n\ntrain_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers = 4, pin_memory = True, drop_last = True)\ntest_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, num_workers = 4, pin_memory = True)\n\nmodel = UNET()\nmodel = model.to(device)\n\nopt = torch.optim.Adam(model.parameters(), lr=LR)\nscaler = torch.amp.GradScaler('cuda')\n\nscheduler = CosineAnnealingLR(opt, T_max = 10, eta_min=1e-6)\n\nfor epoch in range(EPOCHS):\n    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n    for x, y in loop:\n        x = x.float().to(device)\n        y = y.float().unsqueeze(1).to(device)\n        with torch.amp.autocast(device):\n            preds = model(x)\n            loss = loss_fn(preds, y)\n        opt.zero_grad()\n        scaler.scale(loss).backward()\n        scaler.step(opt)\n        scaler.update()\n        loop.set_postfix(loss=loss.item())\n        \n    scheduler.step() \n\n    if ((epoch+1)%5 == 0) or ((epoch+1) == EPOCHS):\n        print(f\"\\n--- Running Validation for Epoch {epoch+1} ---\\n\")\n        \n        check_accuracy(test_loader, model, device)\n        \n        save_sample_predictions(test_loader, model, folder=\"saved_images\", device=device, threshold = 0.65)\n        print(\"\\n---------PREDICTIONS SAVED---------\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T06:55:05.731881Z","iopub.execute_input":"2025-11-25T06:55:05.732273Z","iopub.status.idle":"2025-11-25T08:45:39.039419Z","shell.execute_reply.started":"2025-11-25T06:55:05.732248Z","shell.execute_reply":"2025-11-25T08:45:39.038364Z"}},"outputs":[{"name":"stderr","text":"Epoch 1/25: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 166/166 [04:11<00:00,  1.52s/it, loss=0.309]\nEpoch 2/25: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 166/166 [03:59<00:00,  1.44s/it, loss=0.273]\nEpoch 3/25: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 166/166 [04:01<00:00,  1.46s/it, loss=0.24] \nEpoch 4/25: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 166/166 [04:01<00:00,  1.45s/it, loss=0.218]\nEpoch 5/25: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 166/166 [04:07<00:00,  1.49s/it, loss=0.174]","output_type":"stream"},{"name":"stdout","text":"\n--- Running Validation for Epoch 5 ---\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"DICE SCORE: tensor(0.8513, device='cuda:0')\nSaving 10 prediction comparisons using threshold=0.65\n\n---------PREDICTIONS SAVED---------\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/25: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 166/166 [04:17<00:00,  1.55s/it, loss=0.191]\nEpoch 7/25: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 166/166 [04:17<00:00,  1.55s/it, loss=0.186]\nEpoch 8/25: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 166/166 [04:16<00:00,  1.55s/it, loss=0.193]\nEpoch 9/25: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 166/166 [04:16<00:00,  1.55s/it, loss=0.165]\nEpoch 10/25: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 166/166 [04:04<00:00,  1.47s/it, loss=0.19] ","output_type":"stream"},{"name":"stdout","text":"\n--- Running Validation for Epoch 10 ---\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"DICE SCORE: tensor(0.9251, device='cuda:0')\nSaving 10 prediction comparisons using threshold=0.65\n\n---------PREDICTIONS SAVED---------\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11/25: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 166/166 [04:00<00:00,  1.45s/it, loss=0.157]\nEpoch 12/25: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 166/166 [04:02<00:00,  1.46s/it, loss=0.155]\nEpoch 13/25: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 166/166 [04:04<00:00,  1.47s/it, loss=0.156]\nEpoch 14/25: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 166/166 [04:03<00:00,  1.46s/it, loss=0.162]\nEpoch 15/25: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 166/166 [04:03<00:00,  1.47s/it, loss=0.171]","output_type":"stream"},{"name":"stdout","text":"\n--- Running Validation for Epoch 15 ---\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"DICE SCORE: tensor(0.8959, device='cuda:0')\nSaving 10 prediction comparisons using threshold=0.65\n\n---------PREDICTIONS SAVED---------\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 16/25: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 166/166 [04:00<00:00,  1.45s/it, loss=0.117] \nEpoch 17/25: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 166/166 [04:03<00:00,  1.47s/it, loss=0.153] \nEpoch 18/25: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 166/166 [04:03<00:00,  1.47s/it, loss=0.096]\nEpoch 19/25: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 166/166 [04:04<00:00,  1.47s/it, loss=0.178] \nEpoch 20/25: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 166/166 [04:03<00:00,  1.46s/it, loss=0.141] ","output_type":"stream"},{"name":"stdout","text":"\n--- Running Validation for Epoch 20 ---\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"DICE SCORE: tensor(0.9010, device='cuda:0')\nSaving 10 prediction comparisons using threshold=0.65\n\n---------PREDICTIONS SAVED---------\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 21/25: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 166/166 [04:01<00:00,  1.46s/it, loss=0.101] \nEpoch 22/25: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 166/166 [04:03<00:00,  1.47s/it, loss=0.0982]\nEpoch 23/25: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 166/166 [04:03<00:00,  1.46s/it, loss=0.113] \nEpoch 24/25: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 166/166 [04:03<00:00,  1.47s/it, loss=0.0652]\nEpoch 25/25: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 166/166 [04:03<00:00,  1.47s/it, loss=0.04]  ","output_type":"stream"},{"name":"stdout","text":"\n--- Running Validation for Epoch 25 ---\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"DICE SCORE: tensor(0.9388, device='cuda:0')\nSaving 10 prediction comparisons using threshold=0.65\n\n---------PREDICTIONS SAVED---------\n\n","output_type":"stream"}],"execution_count":10}]}