{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6308266,"sourceType":"datasetVersion","datasetId":3629391}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip uninstall -y numpy\n!pip install --quiet numpy==1.26.4\n\n!pip uninstall -y opencv-python opencv-python-headless\n!pip install --quiet opencv-python-headless==4.8.1.78\n\n!pip uninstall -y albumentations qudida scikit-image scipy scikit-learn imgaug\n!pip install --quiet albumentations==1.3.1\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os; os._exit(0)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-11-09T10:29:32.355Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(torch.cuda.device_count(), \"GPUs available\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T10:29:55.553991Z","iopub.execute_input":"2025-11-09T10:29:55.554426Z","iopub.status.idle":"2025-11-09T10:29:55.589202Z","shell.execute_reply.started":"2025-11-09T10:29:55.554404Z","shell.execute_reply":"2025-11-09T10:29:55.588593Z"}},"outputs":[{"name":"stdout","text":"2 GPUs available\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"torch.backends.cudnn.benchmark = True\n!nvidia-smi","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T10:29:57.450530Z","iopub.execute_input":"2025-11-09T10:29:57.450811Z","iopub.status.idle":"2025-11-09T10:29:57.687691Z","shell.execute_reply.started":"2025-11-09T10:29:57.450790Z","shell.execute_reply":"2025-11-09T10:29:57.686941Z"}},"outputs":[{"name":"stdout","text":"Sun Nov  9 10:29:57 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n| N/A   64C    P8             10W /   70W |       1MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n| N/A   62C    P8             11W /   70W |       1MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torchvision\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nimport numpy as np\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom tqdm import tqdm\nimport cv2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T10:29:41.126887Z","iopub.execute_input":"2025-11-09T10:29:41.127549Z","iopub.status.idle":"2025-11-09T10:29:44.606902Z","shell.execute_reply.started":"2025-11-09T10:29:41.127523Z","shell.execute_reply":"2025-11-09T10:29:44.606311Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"device = ('cuda' if torch.cuda.is_available else 'cpu')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T10:30:00.454338Z","iopub.execute_input":"2025-11-09T10:30:00.455001Z","iopub.status.idle":"2025-11-09T10:30:00.459122Z","shell.execute_reply.started":"2025-11-09T10:30:00.454974Z","shell.execute_reply":"2025-11-09T10:30:00.458366Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"mask_dir = r\"/kaggle/input/fs2020-runway-dataset/labels/labels/areas/train_labels_1920x1080\"\ntest_mask_dir = r\"/kaggle/input/fs2020-runway-dataset/labels/labels/areas/test_labels_1920x1080\"\nbinary_mask_dir = r\"/kaggle/working/binary_mask\"\nbinary_test_mask_dir = r\"/kaggle/working/binary_test_mask\"\n\ndef convert2Binary(mask_dir, binary_mask_dir):\n    os.makedirs(binary_mask_dir, exist_ok = True)\n    for filename in os.listdir(mask_dir):\n        if not filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n            continue\n        img_path = os.path.join(mask_dir, filename)\n        img = cv2.imread(img_path)\n    \n        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    \n        binary = np.where(gray > 0, 255, 0).astype(np.uint8)\n    \n        cv2.imwrite(os.path.join(binary_mask_dir, filename), binary)\n\n#convert2Binary(test_mask_dir, binary_test_mask_dir)\n#convert2Binary(mask_dir, binary_mask_dir)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T10:30:04.404285Z","iopub.execute_input":"2025-11-09T10:30:04.404877Z","iopub.status.idle":"2025-11-09T10:30:04.410046Z","shell.execute_reply.started":"2025-11-09T10:30:04.404849Z","shell.execute_reply":"2025-11-09T10:30:04.409363Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"\nclass RunwayDataset(Dataset):\n    def __init__(self, img_dir, mask_dir, transform=None):\n        self.img_dir = img_dir\n        self.mask_dir = mask_dir\n        self.transform = transform\n        self.images = os.listdir(img_dir)\n\n    def __len__(self):\n        return len(self.images)\n    \n    def __getitem__(self, index):\n        img_path = os.path.join(self.img_dir, self.images[index])\n        mask_path = os.path.join(self.mask_dir, self.images[index])\n        image = np.array(Image.open(img_path).convert(\"RGB\"))\n        mask = np.array(Image.open(mask_path).convert(\"L\"), dtype=np.float32) / 255.0\n\n        if self.transform is not None:\n            aug = self.transform(image=image, mask=mask)\n            image = aug[\"image\"]\n            mask = aug[\"mask\"]\n            \n        return image, mask\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T10:30:07.171364Z","iopub.execute_input":"2025-11-09T10:30:07.172021Z","iopub.status.idle":"2025-11-09T10:30:07.177529Z","shell.execute_reply.started":"2025-11-09T10:30:07.171997Z","shell.execute_reply":"2025-11-09T10:30:07.176808Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"import torchvision.transforms.functional as TF\n\nclass DoubleConv(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, 3, padding=1, bias=False),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(out_channels, out_channels, 3, padding=1, bias=False),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True),\n        )\n\n    def forward(self, x):\n        return self.conv(x)\n\nclass UNET(nn.Module):\n    def __init__(self, in_channels=3, out_channels=1, features=[64,128,256,512]):\n        super().__init__()\n        self.downs = nn.ModuleList()\n        self.ups = nn.ModuleList()\n        self.pool = nn.MaxPool2d(2)\n\n        for f in features:\n            self.downs.append(DoubleConv(in_channels, f))\n            in_channels = f\n\n        for f in reversed(features):\n            self.ups.append(nn.ConvTranspose2d(f*2, f, kernel_size=2, stride=2))\n            self.ups.append(DoubleConv(f*2, f))\n\n        self.bottleneck = DoubleConv(features[-1], features[-1]*2)\n        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n\n    def forward(self, x):\n        skips = []\n        for down in self.downs:\n            x = down(x)\n            skips.append(x)\n            x = self.pool(x)\n\n        x = self.bottleneck(x)\n        skips = skips[::-1]\n\n        for idx in range(0, len(self.ups), 2):\n            x = self.ups[idx](x)\n            skip = skips[idx//2]\n            if x.shape != skip.shape:\n                x = TF.resize(x, skip.shape[2:])\n            x = torch.cat((skip, x), dim=1)\n            x = self.ups[idx+1](x)\n\n        return self.final_conv(x)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T10:30:11.849481Z","iopub.execute_input":"2025-11-09T10:30:11.850215Z","iopub.status.idle":"2025-11-09T10:30:11.859257Z","shell.execute_reply.started":"2025-11-09T10:30:11.850189Z","shell.execute_reply":"2025-11-09T10:30:11.858610Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"class DiceLoss(nn.Module):\n    def __init__(self, smooth=1e-8):\n        super().__init__()\n        self.smooth = smooth\n\n    def forward(self, preds, targets):\n        preds = torch.sigmoid(preds)\n        intersection = (preds * targets).sum()\n        dice = 1 - (2 * intersection + self.smooth) / (preds.sum() + targets.sum() + self.smooth)\n        return dice.mean()\n\n\nclass TrevskyLoss(nn.Module):\n    def __init__(self, alpha = 0.5, beta = 0.5, smooth = 1e-6):\n        super(TrevskyLoss, self).__init__()\n        self.alpha = alpha\n        self.beta = beta\n        self.smooth = smooth\n\n    def forward(self, inputs, targets):\n        probs = torch.sigmoid(inputs)\n        targets = targets.float()\n\n        tp = (probs*targets).sum(dim = (1,2,3))\n        fp = ((1 - targets)*probs).sum(dim = (1,2,3))\n        fn = ((1-probs)*targets).sum(dim = (1,2,3))\n\n        ti = (self.smooth + tp)/(tp+ self.alpha*fp + self.beta*fn)\n        loss = 1 - ti\n        return loss.mean()\n\n\nclass FocalTrevsky(nn.Module):\n    def __init__(self, alpha = 0.5, beta = 0.5, gamma = 1.33, smooth = 1e-6):\n        super(FocalTrevsky, self).__init__()\n        self.alpha = alpha\n        self.beta = beta\n        self.smooth = smooth\n        self.gamma = gamma\n\n    def forward(self, inputs, targets):\n        probs = torch.sigmoid(inputs)\n        targets = targets.float()\n\n        tp = (probs*targets).sum(dim = (1,2,3))\n        fp = ((1 - targets)*probs).sum(dim = (1,2,3))\n        fn = ((1-probs)*targets).sum(dim = (1,2,3))\n\n        ti = (self.smooth + tp)/(tp+ self.alpha*fp + self.beta*fn)\n        loss = (1 - ti)**self.gamma\n        focalloss = loss.mean()\n        return focalloss\n\n\n\n\n\ndef check_accuracy(loader, model, device=\"cuda\"):\n    dice = 0\n    with torch.no_grad():\n        for x, y in loader:\n            x = x.to(device)\n            y = y.to(device).unsqueeze(1)\n            preds = torch.sigmoid(model(x))\n            preds = (preds > 0.5).float()\n            intersection = (preds * y).sum()\n            dice += (2*intersection + 1e-8) / (preds.sum() + y.sum() + 1e-8)\n    print(\"DICE SCORE:\", dice/len(loader))\n    model.train()\n\ndef save_sample_predictions(loader, model, folder=\"saved_images/\", device=\"cuda\", num_images_to_save = 10):\n    os.makedirs(folder, exist_ok=True)\n    model.eval()\n\n    try:\n        x, y =  next(iter(loader))\n    except StopIteration:\n        print(\"TEST LOADER IS EMPTY\")\n        return\n    x.to(device)\n    y.to(device)\n\n    with torch.no_grad():\n        preds = (torch.sigmoid(model(x)) > 0.5).float()\n    \n    num_to_save = min(num_images_to_save, x.shape[0])\n    print(f\"Saving {num_to_save} detailed prediction sets...\")\n    for i in range(num_to_save):\n        img_tensor = x[i]\n        mask_tensor = y[i].unsqueeze(0)\n        pred_tensor = preds[i]\n\n\n        mask_rgb = mask_tensor.repeat(3, 1, 1)\n        pred_rgb = pred_tensor.repeat(3, 1, 1)\n\n        combined_image = torch.cat([img_tensor, mask_rgb, pred_rgb], dim=2)\n\n        save_path = os.path.join(folder, f\"comparison_sample_{i}.png\")\n\n        torchvision.utils.save_image(combined_image, save_path)\n    model.train()\n\ndef auto_find_max_batch(model, dataset, start=4, max_try=64, device=\"cuda\"):\n    \"\"\"\n    Tries batch sizes: start, start+2, start+4, ... until OOM.\n    Returns the largest stable batch size.\n    \"\"\"\n    batch = start\n    last_good = start\n\n    while batch <= max_try:\n        try:\n            loader = DataLoader(dataset, batch_size=batch, shuffle=True)\n            x, y = next(iter(loader))\n            x = x.to(device)\n            y = y.float().unsqueeze(1).to(device)\n\n            # Run a small forward & backward to test capacity\n            with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n                out = model(x)\n                loss = (out.mean() - y.mean()).abs()\n\n            loss.backward()\n            torch.cuda.empty_cache()\n\n            print(f\"✅ Batch {batch} worked\")\n            last_good = batch\n            batch += 2  # Increase step size\n\n        except RuntimeError as e:\n            if \"out of memory\" in str(e).lower():\n                print(f\"❌ OOM at batch {batch}\")\n                torch.cuda.empty_cache()\n                break\n            else:\n                raise e\n\n    return last_good\n\ndef save_predictions_as_imgs(loader, model, folder=\"saved_images/\", device=\"cuda\"):\n    os.makedirs(folder, exist_ok=True)\n    model.eval()\n    for idx, (x, y) in enumerate(loader):\n        x = x.to(device)\n        with torch.no_grad():\n            preds = (torch.sigmoid(model(x)) > 0.5).float()\n        torchvision.utils.save_image(preds, f\"{folder}/pred_{idx}.png\")\n        torchvision.utils.save_image(y.unsqueeze(1), f\"{folder}/mask_{idx}.png\")\n    model.train()\n\npos_weight = torch.tensor([5.0]).to(device)\nbce_loss = nn.BCEWithLogitsLoss(pos_weight = pos_weight)\ndice_loss = DiceLoss()\nfocalTrevsky = FocalTrevsky(alpha = 0.7, beta = 0.3)\n\ndef loss_fn(preds, targets):\n    bce = bce_loss(preds, targets)\n    dice = dice_loss(preds, targets)\n    trevsky = focalTrevsky(preds, targets)\n    return 0.8*bce + 0.2*trevsky\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T11:30:10.902114Z","iopub.execute_input":"2025-11-09T11:30:10.902717Z","iopub.status.idle":"2025-11-09T11:30:10.921090Z","shell.execute_reply.started":"2025-11-09T11:30:10.902693Z","shell.execute_reply":"2025-11-09T11:30:10.920395Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# Paths must be changed to match your Kaggle dataset paths:\nTRAIN_IMG_DIR = \"/kaggle/input/fs2020-runway-dataset/1920x1080/1920x1080/train\"\nTRAIN_MASK_DIR = r\"/kaggle/working/binary_mask\"\nTEST_IMG_DIR = \"/kaggle/input/fs2020-runway-dataset/1920x1080/1920x1080/test\"\nTEST_MASK_DIR = \"/kaggle/working/binary_test_mask\"\n\nBATCH_SIZE = 58\nLR = 1e-4\nEPOCHS = 25\nIMG_H, IMG_W = 288, 512\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\ntrain_tf = A.Compose([\n    A.Resize(IMG_H, IMG_W),\n    A.Rotate(limit=35, p=1.0),\n    A.HorizontalFlip(p=0.5),\n    A.Normalize(mean=0, std=1, max_pixel_value=255),\n    ToTensorV2(),\n])\n\ntest_tf = A.Compose([\n    A.Resize(IMG_H, IMG_W),\n    A.Normalize(mean=0, std=1, max_pixel_value=255),\n    ToTensorV2(),\n])\n\ntrain_ds = RunwayDataset(TRAIN_IMG_DIR, TRAIN_MASK_DIR, train_tf)\ntest_ds = RunwayDataset(TEST_IMG_DIR, TEST_MASK_DIR, test_tf)\n\ntrain_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers = 4, pin_memory = True)\ntest_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, num_workers = 4, pin_memory = True)\n\nmodel = UNET()\nmodel = torch.nn.DataParallel(model) \nmodel = model.to(device)\n\nopt = torch.optim.Adam(model.parameters(), lr=LR)\nscaler = torch.amp.GradScaler(device)\n\nfor epoch in range(EPOCHS):\n    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n    for x, y in loop:\n        x, y = x.to(device), y.float().unsqueeze(1).to(device)\n        with torch.amp.autocast(device):\n            preds = model(x)\n            loss = loss_fn(preds, y)\n        opt.zero_grad()\n        scaler.scale(loss).backward()\n        scaler.step(opt)\n        scaler.update()\n        loop.set_postfix(loss=loss.item())\n\n    if ((epoch+1)%5 == 0) or ((epoch+1) == EPOCHS):\n        print(f\"\\n--- Running Validation for Epoch {epoch+1} ---\\n\")\n        check_accuracy(test_loader, model, device)\n        print(\"SAVING PREDICIONS........\")\n        save_sample_predictions(test_loader, model, folder=\"saved_images\", device=device)\n        print(\"\\n---------PREDICTIONS SAVED---------\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T11:30:15.506557Z","iopub.execute_input":"2025-11-09T11:30:15.506829Z","iopub.status.idle":"2025-11-09T13:03:50.225146Z","shell.execute_reply.started":"2025-11-09T11:30:15.506808Z","shell.execute_reply":"2025-11-09T13:03:50.224049Z"}},"outputs":[{"name":"stderr","text":"Epoch 1/25: 100%|██████████| 69/69 [13:15<00:00, 11.52s/it, loss=0.522]\nEpoch 2/25: 100%|██████████| 69/69 [13:15<00:00, 11.53s/it, loss=0.505]\nEpoch 3/25: 100%|██████████| 69/69 [13:15<00:00, 11.53s/it, loss=0.421]\nEpoch 4/25: 100%|██████████| 69/69 [13:14<00:00, 11.52s/it, loss=0.445]\nEpoch 5/25: 100%|██████████| 69/69 [13:13<00:00, 11.50s/it, loss=0.434]","output_type":"stream"},{"name":"stdout","text":"\n--- Running Validation for Epoch 5 ---\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"DICE SCORE: tensor(0.6652, device='cuda:0')\nSAVING PREDICIONS........\nSaving 10 detailed prediction sets...\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_281/2033302030.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mcheck_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SAVING PREDICIONS........\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0msave_sample_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"saved_images\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n---------PREDICTIONS SAVED---------\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_281/4081588935.py\u001b[0m in \u001b[0;36msave_sample_predictions\u001b[0;34m(loader, model, folder, device, num_images_to_save)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mpred_rgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0mcombined_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_rgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_rgb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0msave_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"comparison_sample_{i}.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument tensors in method wrapper_CUDA_cat)"],"ename":"RuntimeError","evalue":"Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument tensors in method wrapper_CUDA_cat)","output_type":"error"}],"execution_count":14}]}